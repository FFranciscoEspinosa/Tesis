{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1efe622f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import hamming\n",
    "import gudhi as gd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84be2c16",
   "metadata": {},
   "source": [
    "<h3>Se cargan los datos</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d451b8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se cargan las coincidencias obtenidas por el BBH\n",
    "pseudo_csv=pd.read_csv('pseudo.csv', sep='\\t', header=None,index_col=0)\n",
    "\n",
    "#Se cargan los nombres comunes de las especies\n",
    "#pseudo_nombres=pd.read_csv('/files/francisco_esp/Pseudomonas/Pseudomonas.ids', sep='\\t', header=None, dtype=str)\n",
    "#pseudo_nombres.set_index(1,inplace=True)\n",
    "pseudo_csv.drop(np.NaN,inplace=True)\n",
    "pseudo_csv.reset_index(inplace=True)\n",
    "pseudo_csv.drop(columns=0,inplace=True)\n",
    "pseudo_csv\n",
    "\n",
    "pseudo_info=pseudo_csv[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c66eb336-851d-4277-aecd-8336ceadf56d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6666666.136315.1646 -&gt; calcium-dependent-antib...</td>\n",
       "      <td>gi|6666666.136315.1646|6666666.136315|AHZY01|A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6666666.134953.3589 -&gt; polyketide|215|215_1|21...</td>\n",
       "      <td>gi|6666666.134953.3589|6666666.134953|AKCL01|C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6666666.136574.4344 -&gt; OXALACETATE_AMINOACIDS|...</td>\n",
       "      <td>gi|6666666.136574.4344|6666666.136574|ATKI01|A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6666666.135439.1862 -&gt; 3PGA_AMINOACIDS|6|Cyste...</td>\n",
       "      <td>gi|6666666.135439.1862|6666666.135439|JXDG01|C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6666666.136502.4654 -&gt; ALPHAKETOGLUTARATE_AMIN...</td>\n",
       "      <td>gi|6666666.136502.4654|6666666.136502|ATLO01|A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12128</th>\n",
       "      <td>6666666.102116.464 -&gt; ALPHAKETOGLUTARATE_AMINO...</td>\n",
       "      <td>gi|6666666.102116.464|6666666.102116|NC_015379...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12129</th>\n",
       "      <td>6666666.94971.5998 -&gt; ALPHAKETOGLUTARATE_AMINO...</td>\n",
       "      <td>gi|6666666.94971.5998|6666666.94971|201|Glutam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12130</th>\n",
       "      <td>6666666.102121.2566 -&gt; ALPHAKETOGLUTARATE_AMIN...</td>\n",
       "      <td>gi|6666666.102121.2566|6666666.102121|AJXG01|N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12131</th>\n",
       "      <td>6666666.139474.787 -&gt; TCA|1|Citrate_synthase_2...</td>\n",
       "      <td>gi|6666666.139474.787|6666666.139474|LFMR01|Ci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12132</th>\n",
       "      <td>6666666.135434.3838 -&gt; TCA|12|fumarate_hydrata...</td>\n",
       "      <td>gi|6666666.135434.3838|6666666.135434|JYHB01|F...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12133 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       1  \\\n",
       "0      6666666.136315.1646 -> calcium-dependent-antib...   \n",
       "1      6666666.134953.3589 -> polyketide|215|215_1|21...   \n",
       "2      6666666.136574.4344 -> OXALACETATE_AMINOACIDS|...   \n",
       "3      6666666.135439.1862 -> 3PGA_AMINOACIDS|6|Cyste...   \n",
       "4      6666666.136502.4654 -> ALPHAKETOGLUTARATE_AMIN...   \n",
       "...                                                  ...   \n",
       "12128  6666666.102116.464 -> ALPHAKETOGLUTARATE_AMINO...   \n",
       "12129  6666666.94971.5998 -> ALPHAKETOGLUTARATE_AMINO...   \n",
       "12130  6666666.102121.2566 -> ALPHAKETOGLUTARATE_AMIN...   \n",
       "12131  6666666.139474.787 -> TCA|1|Citrate_synthase_2...   \n",
       "12132  6666666.135434.3838 -> TCA|12|fumarate_hydrata...   \n",
       "\n",
       "                                                       2  \n",
       "0      gi|6666666.136315.1646|6666666.136315|AHZY01|A...  \n",
       "1      gi|6666666.134953.3589|6666666.134953|AKCL01|C...  \n",
       "2      gi|6666666.136574.4344|6666666.136574|ATKI01|A...  \n",
       "3      gi|6666666.135439.1862|6666666.135439|JXDG01|C...  \n",
       "4      gi|6666666.136502.4654|6666666.136502|ATLO01|A...  \n",
       "...                                                  ...  \n",
       "12128  gi|6666666.102116.464|6666666.102116|NC_015379...  \n",
       "12129  gi|6666666.94971.5998|6666666.94971|201|Glutam...  \n",
       "12130  gi|6666666.102121.2566|6666666.102121|AJXG01|N...  \n",
       "12131  gi|6666666.139474.787|6666666.139474|LFMR01|Ci...  \n",
       "12132  gi|6666666.135434.3838|6666666.135434|JYHB01|F...  \n",
       "\n",
       "[12133 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pseudo_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22a82900-13c3-48b6-8c48-2b0fd96bcfd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        gi|6666666.136315.1646|6666666.136315|AHZY01|A...\n",
       "1        gi|6666666.134953.3589|6666666.134953|AKCL01|C...\n",
       "2        gi|6666666.136574.4344|6666666.136574|ATKI01|A...\n",
       "3        gi|6666666.135439.1862|6666666.135439|JXDG01|C...\n",
       "4        gi|6666666.136502.4654|6666666.136502|ATLO01|A...\n",
       "                               ...                        \n",
       "12128    gi|6666666.102116.464|6666666.102116|NC_015379...\n",
       "12129    gi|6666666.94971.5998|6666666.94971|201|Glutam...\n",
       "12130    gi|6666666.102121.2566|6666666.102121|AJXG01|N...\n",
       "12131    gi|6666666.139474.787|6666666.139474|LFMR01|Ci...\n",
       "12132    gi|6666666.135434.3838|6666666.135434|JYHB01|F...\n",
       "Name: 2, Length: 12133, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pseudo_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51244455-dc45-4466-8dbf-61e62f2b6b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_info[1]=pseudo_info[1].replace('6666666.134953','h')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ad5378",
   "metadata": {},
   "source": [
    "<h3>Con las siguientes funciones se depuran los datos y se elabora el data frame de presencia </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e2856e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_presence(info):\n",
    "    genomes=set()\n",
    "    functions=set()\n",
    "    for name in info:\n",
    "        split=name.split('|')\n",
    "        genomes.add(split[-1])\n",
    "        functions.add(split[4])\n",
    "    presence=pd.DataFrame(index=list(genomes),columns=list(functions))\n",
    "    presence=full_presence(info,presence)\n",
    "    return presence.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49742869",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_presence(info,presence):\n",
    "    for name in info:\n",
    "        split=name.split('|')\n",
    "        presence.loc[split[-1],split[4]]=1\n",
    "    return presence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98496332-0152-41ed-bf57-c918dcb9d81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_presence=get_presence(pseudo_info)\n",
    "pseudo_presence.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de82cf97-1a22-40d0-9828-2e987ee72066",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_presence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b56cf63-13f8-4356-aacf-2a7c3e79f55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_presence.drop('PseudomonasindicaNBRC103045',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e22f3f7-9309-4bce-bfd4-61f031423f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "orden=pseudo_presence.sum(axis=1)\n",
    "pseudo_presence['orden']=orden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3d7094-3980-4344-b90f-50182e56c20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_presence.sort_values(by=['orden'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e7e880-0b13-4f7b-8c44-9031a2436ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_presence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d3bdc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's assume that \"population\" is a numpy ndarray with your genomes as rows.\n",
    "def calculate_hamming_matrix(population):\n",
    "    # Number of genomes\n",
    "    num_genomes = population.shape[0]\n",
    "    # Create an empty matrix for Hamming distances\n",
    "    hamming_matrix = np.zeros((num_genomes, num_genomes), dtype=int)\n",
    "   # Calculate the Hamming distance between each pair of genomes\n",
    "    for i in range(num_genomes):\n",
    "        for j in range(i+1, num_genomes):  # j=i+1 to avoid calculating the same distance twice\n",
    "            # The Hamming distance is multiplied by the number of genes to convert it into an absolute distance\n",
    "            distance = hamming(population[i], population[j]) * len(population[i])\n",
    "            hamming_matrix[i, j] = distance\n",
    "            hamming_matrix[j, i] = distance  # The matrix is symmetric\n",
    "    \n",
    "    return hamming_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e242ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_complex(distance_matrix2):\n",
    "    # Create the Rips simplicial complex from the distance matrix\n",
    "    rips_complex = gd.RipsComplex(distance_matrix=distance_matrix2)\n",
    "    # Create the simplex tree from the Rips complex with a maximum dimension of 3\n",
    "    simplex_tree = rips_complex.create_simplex_tree(max_dimension=2)\n",
    "    # Compute the persistence of the simplicial complex\n",
    "    persistence = simplex_tree.persistence()\n",
    "    # Return the persistence diagram or barcode\n",
    "    return persistence, simplex_tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19ed433",
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_pseudo=calculate_hamming_matrix(pseudo_presence.drop(columns=['orden']).values)\n",
    "#matriz_actino=calculate_hamming_matrix(actino_presence.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15f60cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_pseudo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06909e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_pseudo.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee475b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_pseudo=create_complex(matriz_pseudo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c004023",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(matriz_pseudo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd348670",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "gd.plot_persistence_barcode(complex_pseudo[0],legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec9a506",
   "metadata": {},
   "outputs": [],
   "source": [
    "gd.plot_persistence_diagram(complex_pseudo[0],legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23f61b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "import gudhi as gd\n",
    "from scipy.spatial.distance import hamming\n",
    "import plotly.graph_objs as go\n",
    "import networkx as nx\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f45bc7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_simplicial_complex(simplex_tree, filtration_value, vertex_names=None, save_filename=None, plot_size=1, dpi=600, pos=None):\n",
    "    G = nx.Graph()\n",
    "    triangles = []  # List to store triangles (3-nodes simplices)\n",
    "    \n",
    "    for simplex, filt in simplex_tree.get_filtration():\n",
    "        if filt <= filtration_value:\n",
    "            if len(simplex) == 2:\n",
    "                G.add_edge(simplex[0], simplex[1])\n",
    "            elif len(simplex) == 1:\n",
    "                G.add_node(simplex[0])\n",
    "            elif len(simplex) == 3:\n",
    "                triangles.append(simplex)\n",
    "    \n",
    "    # Calculate node positions if not provided\n",
    "    if pos is None:\n",
    "        pos = nx.spring_layout(G)\n",
    "    \n",
    "    # Node trace\n",
    "    x_values, y_values = zip(*[pos[node] for node in G.nodes()])\n",
    "    node_labels = [vertex_names[node] if vertex_names else str(node) for node in G.nodes()]\n",
    "    node_trace = go.Scatter(x=x_values, y=y_values, mode='markers+text', hoverinfo='text', marker=dict(size=14), text=node_labels, textposition='top center', textfont=dict(size=14))\n",
    "    \n",
    "    # Edge traces\n",
    "    edge_traces = []\n",
    "    for edge in G.edges():\n",
    "        x0, y0 = pos[edge[0]]\n",
    "        x1, y1 = pos[edge[1]]\n",
    "        edge_trace = go.Scatter(x=[x0, x1, None], y=[y0, y1, None], mode='lines', line=dict(width=3, color='rgba(0,0,0,0.5)'))\n",
    "        edge_traces.append(edge_trace)\n",
    "    \n",
    "    # Triangle traces\n",
    "    triangle_traces = []\n",
    "    for triangle in triangles:\n",
    "        x0, y0 = pos[triangle[0]]\n",
    "        x1, y1 = pos[triangle[1]]\n",
    "        x2, y2 = pos[triangle[2]]\n",
    "        triangle_trace = go.Scatter(x=[x0, x1, x2, x0, None], y=[y0, y1, y2, y0, None], fill='toself', mode='lines+markers', line=dict(width=2), fillcolor='rgba(255,0,0,0.2)')\n",
    "        triangle_traces.append(triangle_trace)\n",
    "    \n",
    "    # Configure the layout of the plot\n",
    "    layout = go.Layout(showlegend=False, hovermode='closest', xaxis=dict(showgrid=False, zeroline=False, tickfont=dict(size=16, family='Arial, sans-serif')), yaxis=dict(showgrid=False, zeroline=False, tickfont=dict(size=16, family='Arial, sans-serif')))\n",
    "    \n",
    "    fig = go.Figure(data=edge_traces + triangle_traces + [node_trace], layout=layout)\n",
    "    \n",
    "    # Set the figure size\n",
    "    fig.update_layout(width=plot_size * dpi, height=plot_size * dpi)\n",
    "    \n",
    "    # Save the figure if a filename is provided\n",
    "    if save_filename:\n",
    "        pio.write_image(fig, save_filename, width=plot_size * dpi, height=plot_size * dpi, scale=1)\n",
    "    \n",
    "    # Show the figure\n",
    "    #fig.show()\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2eeaec-7457-44a6-bda7-167a83e2c594",
   "metadata": {},
   "outputs": [],
   "source": [
    "G=visualize_simplicial_complex(complex_pseudo[1],2)\n",
    "nx.write_graphml(G, \"simplex_complex.graphml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993361e7-9c08-486a-b017-76bf7831c1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx.utils import not_implemented_for, pairwise\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "def minimum_cycle_basis(G, weight=None, total=None):\n",
    "    \"\"\"Returns a minimum weight cycle basis for G\n",
    "\n",
    "    Minimum weight means a cycle basis for which the total weight\n",
    "    (length for unweighted graphs) of all the cycles is minimum.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    G : NetworkX Graph\n",
    "    weight: string\n",
    "        name of the edge attribute to use for edge weights\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A list of cycle lists.  Each cycle list is a list of nodes\n",
    "    which forms a cycle (loop) in G. Note that the nodes are not\n",
    "    necessarily returned in an order by which they appear in the cycle\n",
    "    \"\"\"\n",
    "    # Get connected components\n",
    "    components = list(nx.connected_components(G))\n",
    "    print(components)\n",
    "    # Use ThreadPoolExecutor to parallelize the computation\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        # Submit tasks for each connected component\n",
    "        future_to_component = {\n",
    "            executor.submit(_min_cycle_basis, G.subgraph(component), weight, total): component\n",
    "            for component in components\n",
    "        }\n",
    "        \n",
    "        # Collect results as they complete\n",
    "        results = []\n",
    "        for future in as_completed(future_to_component):\n",
    "            component = future_to_component[future]\n",
    "            try:\n",
    "                result = future.result()\n",
    "                results.extend(result)\n",
    "            except Exception as exc:\n",
    "                print(f\"Component {component} generated an exception: {exc}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "def _min_cycle_basis(G, weight,total):\n",
    "    cb = []\n",
    "    cont=0\n",
    "    # We  extract the edges not in a spanning tree. We do not really need a\n",
    "    # *minimum* spanning tree. That is why we call the next function with\n",
    "    # weight=None. Depending on implementation, it may be faster as well\n",
    "    tree_edges = list(nx.minimum_spanning_edges(G, weight=None, data=False))\n",
    "    chords = G.edges - tree_edges - {(v, u) for u, v in tree_edges}\n",
    "\n",
    "    # We maintain a set of vectors orthogonal to sofar found cycles\n",
    "    set_orth = [{edge} for edge in chords]\n",
    "    while set_orth:\n",
    "        if cont==total:\n",
    "            break\n",
    "        base = set_orth.pop()\n",
    "        # kth cycle is \"parallel\" to kth vector in set_orth\n",
    "        cycle_edges = _min_cycle(G, base, weight)\n",
    "        cycle_found=[v for u, v in cycle_edges]\n",
    "\n",
    "        if len(cycle_found)>3:\n",
    "            cb.append(cycle_found)\n",
    "            cont+=1\n",
    "\n",
    "        # now update set_orth so that k+1,k+2... th elements are\n",
    "        # orthogonal to the newly found cycle, as per [p. 336, 1]\n",
    "        set_orth = [\n",
    "            (\n",
    "                {e for e in orth if e not in base if e[::-1] not in base}\n",
    "                | {e for e in base if e not in orth if e[::-1] not in orth}\n",
    "            )\n",
    "            if sum((e in orth or e[::-1] in orth) for e in cycle_edges) % 2\n",
    "            else orth\n",
    "            for orth in set_orth\n",
    "        ]\n",
    "    return cb\n",
    "\n",
    "\n",
    "def _min_cycle(G, orth, weight):\n",
    "    \"\"\"\n",
    "    Computes the minimum weight cycle in G,\n",
    "    orthogonal to the vector orth as per [p. 338, 1]\n",
    "    Use (u, 1) to indicate the lifted copy of u (denoted u' in paper).\n",
    "    \"\"\"\n",
    "    Gi = nx.Graph()\n",
    "\n",
    "    # Add 2 copies of each edge in G to Gi.\n",
    "    # If edge is in orth, add cross edge; otherwise in-plane edge\n",
    "    for u, v, wt in G.edges(data=weight, default=1):\n",
    "        if (u, v) in orth or (v, u) in orth:\n",
    "            Gi.add_edges_from([(u, (v, 1)), ((u, 1), v)], Gi_weight=wt)\n",
    "        else:\n",
    "            Gi.add_edges_from([(u, v), ((u, 1), (v, 1))], Gi_weight=wt)\n",
    "\n",
    "    # find the shortest length in Gi between n and (n, 1) for each n\n",
    "    # Note: Use \"Gi_weight\" for name of weight attribute\n",
    "    spl = nx.shortest_path_length\n",
    "    lift = {n: spl(Gi, source=n, target=(n, 1), weight=\"Gi_weight\") for n in G}\n",
    "\n",
    "    # Now compute that short path in Gi, which translates to a cycle in G\n",
    "    start = min(lift, key=lift.get)\n",
    "    end = (start, 1)\n",
    "    min_path_i = nx.shortest_path(Gi, source=start, target=end, weight=\"Gi_weight\")\n",
    "\n",
    "    # Now we obtain the actual path, re-map nodes in Gi to those in G\n",
    "    min_path = [n if n in G else n[0] for n in min_path_i]\n",
    "\n",
    "    # Now remove the edges that occur two times\n",
    "    # two passes: flag which edges get kept, then build it\n",
    "    edgelist = list(pairwise(min_path))\n",
    "    edgeset = set()\n",
    "    for e in edgelist:\n",
    "        if e in edgeset:\n",
    "            edgeset.remove(e)\n",
    "        elif e[::-1] in edgeset:\n",
    "            edgeset.remove(e[::-1])\n",
    "        else:\n",
    "            edgeset.add(e)\n",
    "\n",
    "    min_edgelist = []\n",
    "    for e in edgelist:\n",
    "        if e in edgeset:\n",
    "            min_edgelist.append(e)\n",
    "            edgeset.remove(e)\n",
    "        elif e[::-1] in edgeset:\n",
    "            min_edgelist.append(e[::-1])\n",
    "            edgeset.remove(e[::-1])\n",
    "\n",
    "    return min_edgelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d137af93",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_all_cycles(simplex_tree,persistence):\n",
    "    born_and_number = born_filtraton_value_holes(persistence)\n",
    "    G=nx.Graph()\n",
    "    born=born_and_number.keys()\n",
    "    ciclos_dep=set()\n",
    "    filtration=0\n",
    "    for simplex, filt in simplex_tree.get_filtration():\n",
    "        #if len(ciclos_dep)==num_holes:\n",
    "         #   break\n",
    "        \n",
    "        if filtration!=filt and filtration in born:\n",
    "            number=born_and_number[filtration]\n",
    "            print('se buscan ciclos en el tiempo', filt)\n",
    "            ciclos=minimum_cycle_basis(G,total=number)\n",
    "            for ciclo in ciclos:\n",
    "                if len(ciclo)>3:\n",
    "                    print('Se encontró el ciclo',ciclo,'en el tiempo', filtration)\n",
    "                    ciclos_dep.add(tuple(ciclo))\n",
    "                    #Se llena el hoyo\n",
    "                    for i in ciclo:\n",
    "                        for j in ciclo:\n",
    "                            G.add_edge(i,j)\n",
    "                            \n",
    "            \n",
    "        filtration=filt\n",
    "        \n",
    "        if len(simplex)==2:\n",
    "            G.add_edge(simplex[0], simplex[1])\n",
    "\n",
    "        \n",
    "\n",
    "    return ciclos_dep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ab3799",
   "metadata": {},
   "outputs": [],
   "source": [
    "def born_filtraton_value_holes(persistence):\n",
    "    born=[]\n",
    "    for bar in persistence:\n",
    "        if bar[0]==1:\n",
    "            born.append(bar[1][0])\n",
    "            \n",
    "    born_and_number=set([(x,born.count(x)) for x  in born])\n",
    "\n",
    "    return dict(born_and_number)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dda485c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ciclos_pseudo=find_all_cycles(complex_pseudo[1],complex_pseudo[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1f15a7-b857-461e-bf11-f1d80fbceb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "ciclos_pseudo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bc0dcd-3d16-459f-9de7-a0f7dab664b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "\n",
    "def find_cycles_at_filtration(G, filtration, born_and_number):\n",
    "    born=born_and_number.keys()\n",
    "    ciclos_dep = set()\n",
    "    if filtration in born:\n",
    "        number=born_and_number[filtration]\n",
    "        print('se buscan',number,'ciclos')\n",
    "        ciclos = minimum_cycle_basis(G,total=20)\n",
    "        print('Se encontraron los ciclos',ciclos)\n",
    "        for ciclo in ciclos:\n",
    "            ciclos_dep.add(tuple(ciclo))\n",
    "                #Se llena el hoyo\n",
    "            for i in ciclo:\n",
    "                for j in ciclo:\n",
    "                    G.add_edge(i, j)\n",
    "    return ciclos_dep\n",
    "\n",
    "def find_all_cycles(simplex_tree, persistence):\n",
    "    born_and_number = born_filtraton_value_holes(persistence)\n",
    "    \n",
    "    G = nx.Graph()\n",
    "    ciclos_dep = set()\n",
    "    filtration = 0\n",
    "    \n",
    "    with ProcessPoolExecutor() as executor:\n",
    "        futures = []\n",
    "        for simplex, filt in simplex_tree.get_filtration():\n",
    "            if filtration != filt:\n",
    "                future = executor.submit(find_cycles_at_filtration, G.copy(), filtration, born_and_number)\n",
    "                futures.append(future)\n",
    "            filtration = filt\n",
    "            if len(simplex) == 2:\n",
    "                G.add_edge(simplex[0], simplex[1])\n",
    "        \n",
    "        for future in futures:\n",
    "            ciclos_dep.update(future.result())\n",
    "\n",
    "    return ciclos_dep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153b5403-99bd-41f7-9980-683d924348d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "def find_cycle_basis(subgraph):\n",
    "    return list(nx.minimum_cycle_basis(subgraph))\n",
    "\n",
    "def get_subgraphs(graph):\n",
    "    return [graph.subgraph(c) for c in nx.connected_components(graph)]\n",
    "\n",
    "def parallel_minimum_cycle_basis(graph):\n",
    "    subgraphs = get_subgraphs(graph)\n",
    "    with ProcessPoolExecutor() as executor:\n",
    "        results = list(executor.map(find_cycle_basis, subgraphs))\n",
    "    \n",
    "    # Combinar resultados\n",
    "    cycle_basis = [cycle for sublist in results for cycle in sublist]\n",
    "    \n",
    "    return cycle_basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131fd7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "[12,12].count(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af69a131",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing.pool import Pool as ProcessPool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f168436f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with ProcessPool(processes=8) as pool:  # context manager providing a `Pool` instance\n",
    "    result = pool.map(find_all_cycles, complex_pseudo[1],complex_pseudo[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7523155",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "contador=0\n",
    "for i in complex_pseudo[0]:\n",
    "    if i[0]==1:\n",
    "        contador+=1\n",
    "contador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91f4fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "nx.add_cycle(G,[195, 212, 167, 187])\n",
    "nx.add_cycle(G,[212, 116, 150, 187])\n",
    "nx.add_cycle(G,[212, 200, 201, 190])\n",
    "\n",
    "#nx.add_cycle(G,[33, 84, 90, 26])\n",
    "#nx.add_cycle(G,[24, 88, 28, 78])\n",
    "#nx.add_cycle(G,[184, 88, 28, 141])\n",
    "#nx.add_cycle(G,[136, 24, 92, 78])\n",
    "\n",
    "#nx.add_cycle(G,[17, 8, 58, 30])\n",
    "#nx.add_cycle(G,[17, 20, 69, 29])\n",
    "#nx.add_cycle(G,[13, 75, 29, 62])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7382ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(G, with_labels = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320aae59",
   "metadata": {},
   "source": [
    "# complex_pseudo[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2af076b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_cycles(simplex_tree, filtration_value):\n",
    "    G=nx.Graph()\n",
    "    for simplex, filt in simplex_tree.get_filtration():\n",
    "        if filt <= filtration_value:\n",
    "            if len(simplex) == 2:\n",
    "                G.add_edge(simplex[0], simplex[1])\n",
    "    \n",
    "\n",
    "    #ciclos=nx.cycle_basis(G)\n",
    "    ciclos=nx.minimum_cycle_basis(G)\n",
    "    ciclos_dep=set()\n",
    "    for ciclo in ciclos:\n",
    "        if len(ciclo)>3:\n",
    "            print('Se encontró el ciclo',ciclo,'en el tiempo', filtration_value)\n",
    "            ciclos_dep.add(tuple(ciclo))\n",
    "\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64559ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80776198",
   "metadata": {},
   "source": [
    "<h2>Generar transferencia horizontal </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed0d21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutate(genome, prob, mutated_positions):\n",
    "    \"\"\"Performs mutations on a genome with a certain probability.\"\"\"\n",
    "    mutations = []\n",
    "    for i in range(len(genome)):\n",
    "        if not mutated_positions[i] and np.random.rand() < prob:\n",
    "            genome[i] = 1 if genome[i] == 0 else 0\n",
    "            mutations.append(i)\n",
    "            mutated_positions[i] = True\n",
    "    return genome, mutations\n",
    "\n",
    "def create_generation(population, num_offspring, prob, mutated_positions):\n",
    "    \"\"\"Creates a new generation from the existing population.\"\"\"\n",
    "    new_population = []\n",
    "    new_generation_history = []\n",
    "    for idx, genome in enumerate(population):\n",
    "        for _ in range(num_offspring):\n",
    "            new_genome, mutations = mutate(genome.copy(), prob, mutated_positions)\n",
    "            new_population.append(new_genome)\n",
    "            new_generation_history.append({'parent': idx, 'mutations': mutations})\n",
    "    return new_population, new_generation_history\n",
    "\n",
    "def create_population(num_genes, mutation_probability, num_generations, num_offspring, percentage_ones,semilla):\n",
    "    np.random.seed(semilla)\n",
    "\n",
    "    initial_genome = np.random.choice([0, 1], size=num_genes, p=[1-percentage_ones, percentage_ones])\n",
    "    population = [initial_genome]\n",
    "    genome_history = []\n",
    "    global_mutated_positions = np.zeros(num_genes, dtype=bool)\n",
    "\n",
    "    for generation in range(num_generations):\n",
    "        population, generation_history = create_generation(population, num_offspring, mutation_probability, global_mutated_positions)\n",
    "        genome_history.extend(generation_history)\n",
    "        print(f\"Generation {generation+1}: {len(population)} genomes\")\n",
    "        # Uncomment the next line if you want to see the details of each generation\n",
    "        # print(len(population), generation_history)\n",
    "\n",
    "    return population, genome_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb660a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "num_genes = 505\n",
    "mutation_probability = 1 / num_genes\n",
    "num_generations = 7\n",
    "num_offspring = 2\n",
    "percentage_ones = 0.25\n",
    "\n",
    "population, population_genome_history = create_population(num_genes, mutation_probability, num_generations, num_offspring, percentage_ones,42)\n",
    "population = np.array(population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a787ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_genomes(population, num_groups, group_size, num_positions_to_change):\n",
    "    np.random.seed(42)  # Puedes usar cualquier número como semilla\n",
    "\n",
    "    # Crear una copia de la población para evitar modificar el original\n",
    "    modified_population = population.copy()\n",
    "\n",
    "    for _ in range(num_groups):\n",
    "        # Seleccionar genomas de manera aleatoria\n",
    "        genome_indices = np.random.choice(population.shape[0], group_size, replace=False)\n",
    "        \n",
    "        # Elegir un punto de inicio al azar y seleccionar posiciones contiguas para cambiar\n",
    "        start_position = np.random.choice(population.shape[1] - num_positions_to_change)\n",
    "        positions_to_change = np.arange(start_position, start_position + num_positions_to_change)\n",
    "        \n",
    "        for index in genome_indices:\n",
    "            # Cambiar los valores en las posiciones seleccionadas a 1\n",
    "            modified_population[index, positions_to_change] = 1\n",
    "    \n",
    "    return modified_population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92862279",
   "metadata": {},
   "outputs": [],
   "source": [
    "population_2=modify_genomes(population, num_groups=2, group_size=3, num_positions_to_change=population.shape[1]//32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484c695a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hamming_matrix_2 = calculate_hamming_matrix(population_2)\n",
    "#hamming_matrix_2\n",
    "\n",
    "# Print the normalized Hamming distance matrix\n",
    "#print(\"Normalized Hamming Distance Matrix:\")\n",
    "#print(normalized_hamming_matrix_2)\n",
    "persistence2, simplex_tree2 = create_complex(hamming_matrix_2)\n",
    "gd.plot_persistence_barcode(persistence2)\n",
    "gd.plot_persistence_diagram(persistence2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TDA",
   "language": "python",
   "name": "tda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
